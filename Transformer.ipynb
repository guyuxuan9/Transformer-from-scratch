{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrArJtwNZVDY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 4\n",
        "max_seq_length = 5\n",
        "pe = torch.zeros(max_seq_length, d_model)\n",
        "\n",
        "position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "print(position)\n",
        "div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "print(div_term)\n",
        "print(torch.sin(position * div_term), torch.sin(position * div_term).shape)\n",
        "pe[:, 0::2] = torch.sin(position * div_term)\n",
        "pe[:, 1::2] = torch.cos(position * div_term)\n",
        "print(pe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6qENQVhjo9S",
        "outputId": "f745b68d-c9b6-4709-ae60-a676f1d59cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.]])\n",
            "tensor([1.0000, 0.0100])\n",
            "tensor([[ 0.0000,  0.0000],\n",
            "        [ 0.8415,  0.0100],\n",
            "        [ 0.9093,  0.0200],\n",
            "        [ 0.1411,  0.0300],\n",
            "        [-0.7568,  0.0400]]) torch.Size([5, 2])\n",
            "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
            "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
            "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
            "        [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
            "        [-0.7568, -0.6536,  0.0400,  0.9992]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some links\n",
        "- [Code reference](https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb)\n",
        "- [Original Paper -- Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)"
      ],
      "metadata": {
        "id": "0gsl1Vc4RU5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html): base class for all neural network modules. Every model should be subclass of this:\n",
        "\n",
        "```\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        ...\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "        # return output\n",
        "```\n",
        "- model = Model(). No need to call forward like model.forward().\n",
        "- model(x) gives the output\n",
        "\n",
        "# MultiHeadAttention\n",
        "**Intuition**: Each head captures different relationships between words.\n",
        "\n",
        "_NB_: The following code and explanation implements the multihead attention a bit differently from that in the original paper. $Q,K,V \\in \\mathbb{R}^{seq, d_{model}}$\n",
        "\n",
        "Original paper:\n",
        "-  $W_i^Q \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}, \\quad W_i^K \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}, \\quad W_i^V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}, \\quad \\text{and} \\quad W^O \\in \\mathbb{R}^{h \\cdot d_v \\times d_{\\text{model}}}$\n",
        "- These are weight matrix for each head\n",
        "\n",
        "Code below:\n",
        "- $W_i^Q \\in \\mathbb{R}^{d_{\\text{model}} \\times d_{model} }, \\quad W_i^K \\in \\mathbb{R}^{d_{\\text{model}} \\times d_{model} }, \\quad W_i^V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_{model} }, \\quad W^O \\in \\mathbb{R}^{h \\cdot d_v \\times d_{\\text{model}}}$\n",
        "- Only one big weight matrix for $Q,K,V$.\n",
        "- Split the heads after linear transformation.\n",
        "\n",
        "![image](https://github.com/guyuxuan9/UROP_robotic_arm/assets/58468284/5e12311f-dee3-4d09-9dce-90e81c93458c)"
      ],
      "metadata": {
        "id": "JtZPIk3uRyGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy"
      ],
      "metadata": {
        "id": "e04fVIXVR80o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Layer for $Q$, $K$ and $V$\n",
        "\n",
        "$Q_{original} = \\begin{bmatrix}\n",
        "    q_{1,1} & q_{1,2} & \\dots & q_{1,d_{model}} \\\\\n",
        "    q_{2,1} & q_{2,2} & \\dots & q_{2,d_{model}} \\\\\n",
        "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    q_{\\text{seq},1} & q_{\\text{seq},2} & \\dots & q_{\\text{seq},d_{model}} \\\\\n",
        "\\end{bmatrix}$,    $K_{original} = \\begin{bmatrix}\n",
        "    k_{1,1} & k_{1,2} & \\dots & k_{1,d_{model}} \\\\\n",
        "    k_{2,1} & k_{2,2} & \\dots & k_{2,d_{model}} \\\\\n",
        "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    k_{\\text{seq},1} & k_{\\text{seq},2} & \\dots & k_{\\text{seq},d_{model}} \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "The weight matrix $W_Q$ and $W_K$ have the learnable parameters. They are described by the _nn.Linear_ function. They all have dimension ($d_{model}, d_{model}$).\n",
        "\n",
        "$W_Q = \\begin{bmatrix}\n",
        "\\vdots & \\vdots & \\dots & \\vdots \\\\\n",
        "w_1^Q & w_2^Q & \\dots & w_{d_{model}}^Q \\\\\n",
        "\\vdots & \\vdots & \\dots & \\vdots\n",
        "\\end{bmatrix}$ $W_K = \\begin{bmatrix}\n",
        "\\vdots & \\vdots & \\dots & \\vdots \\\\\n",
        "w_1^K & w_2^K & \\dots & w_{d_{model}}^K \\\\\n",
        "\\vdots & \\vdots & \\dots & \\vdots\n",
        "\\end{bmatrix}$\n",
        "\n",
        "By multiplying the original embeddings with the learnable weights, the network can learn more patterns, increasing the expressive power than self-attention.\n",
        "\n",
        "$Q = Q_{original}W_Q = \\begin{bmatrix}\n",
        "    q_{1,1}w_{1,1}^Q & q_{1,2}w_{1,2}^Q & \\dots & q_{1,d_{model}}w_{1,d_{model}}^Q \\\\\n",
        "    q_{2,1}w_{2,1}^Q & q_{2,2}w_{2,2}^Q & \\dots & q_{2,d_{model}}w_{2,d_{model}}^Q \\\\\n",
        "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    q_{\\text{seq},1}w_{\\text{seq},1}^Q & q_{\\text{seq},2}w_{\\text{seq},2}^Q & \\dots & q_{\\text{seq},d_{model}}w_{\\text{seq},d_{model}}^Q \\\\\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "    q_{1,1}' & q_{1,2}' & \\dots & q_{1,d_{model}}' \\\\\n",
        "    q_{2,1}' & q_{2,2}' & \\dots & q_{2,d_{model}}' \\\\\n",
        "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    q_{\\text{seq},1}' & q_{\\text{seq},2}' & \\dots & q_{\\text{seq},d_{model}}' \\\\\n",
        "\\end{bmatrix}$,\n",
        "\n",
        "$K = K_{original}W_K = \\begin{bmatrix}\n",
        "    k_{1,1}' & k_{1,2}' & \\dots & k_{1,d_{model}}' \\\\\n",
        "    k_{2,1}' & k_{2,2}' & \\dots & k_{2,d_{model}}' \\\\\n",
        "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    k_{\\text{seq},1}' & k_{\\text{seq},2}' & \\dots & k_{\\text{seq},d_{model}}' \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c5z982cEY_5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Split heads\n",
        "(batch size, seq length, $d_{model}$) --> (batch size, # heads, seq length, $d_k$)\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "    q_{1,1}' & q_{1,2}' & \\dots & q_{1,d_{model}}' \\\\\n",
        "    q_{2,1}' & q_{2,2}' & \\dots & q_{2,d_{model}}' \\\\\n",
        "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    q_{\\text{seq},1}' & q_{\\text{seq},2}' & \\dots & q_{\\text{seq},d_{model}}' \\\\\n",
        "\\end{bmatrix}$ --> $\\begin{bmatrix}\n",
        "    q_{1,1}' & \\dots & q_{1,k}'  \\\\\n",
        "    q_{2,1}' & \\dots &q_{2,k}'\\\\\n",
        "    \\vdots & \\ddots & \\vdots   \\\\\n",
        "    q_{\\text{seq},1}' & \\dots & q_{\\text{seq},k}' \\\\\n",
        "\\end{bmatrix}$ $\\begin{bmatrix}\n",
        "    q_{1,k+1}' & \\dots & q_{1,2k}'  \\\\\n",
        "    q_{2,k+1}' & \\dots &q_{2,2k}'\\\\\n",
        "    \\vdots & \\ddots & \\vdots   \\\\\n",
        "    q_{\\text{seq},k+1}' & \\dots & q_{\\text{seq},2k}' \\\\\n",
        "\\end{bmatrix}$ ...\n",
        "\n"
      ],
      "metadata": {
        "id": "oEUWpVdojKMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention calculation\n",
        "\n",
        "$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_{k}}}\\right) V$\n",
        "- **Q**: Why scaled? **A**: dot product $q.k = \\sum_{i=1}^{d_k} q_ik_i$. Assume $q$ and $k$ are independent, zero mean and unit variance. $E\\{q.k\\} = 0$, $Var(q.k) = d_k$. If dot products gets larger, it will enter the saturation region of softmax --> vanishing gradient\n",
        "- Attention has shape: (batch size, # heads, seq length,  $d_k$ )"
      ],
      "metadata": {
        "id": "es_wHcPfjPlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine heads\n",
        "(batch size, # heads, seq length,  dk) --> (batch size, seq length, $d_{model}$)"
      ],
      "metadata": {
        "id": "HrgldLUwlu75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\" # d_k = d_v = d_model/num_heads\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.d_k = d_model // num_heads\n",
        "\n",
        "    self.W_q = nn.Linear(d_model, d_model)\n",
        "    self.W_k = nn.Linear(d_model, d_model)\n",
        "    self.W_v = nn.Linear(d_model, d_model)\n",
        "    self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "  def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "  def split_heads(self, x):\n",
        "      batch_size, seq_length, d_model = x.size()\n",
        "      return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "  def combine_heads(self, x):\n",
        "      batch_size, _, seq_length, d_k = x.size()\n",
        "      return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "  def forward(self, Q, K, V, mask=None):\n",
        "      Q = self.split_heads(self.W_q(Q))\n",
        "      K = self.split_heads(self.W_k(K))\n",
        "      V = self.split_heads(self.W_v(V))\n",
        "\n",
        "      attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "      output = self.W_o(self.combine_heads(attn_output))\n",
        "      return output"
      ],
      "metadata": {
        "id": "kql364K-SAmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Position-wise Feed-Forward Networks\n",
        "![image](https://github.com/guyuxuan9/UROP_robotic_arm/assets/58468284/4c2f54fb-27d0-4e19-a99f-0562123240d7)\n"
      ],
      "metadata": {
        "id": "vrHPgIkApIZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))"
      ],
      "metadata": {
        "id": "fRtMzS7Ls1J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional encoding"
      ],
      "metadata": {
        "id": "oT-YWotRs8Z7"
      }
    }
  ]
}